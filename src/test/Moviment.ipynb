{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉ-AMBULO - IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from modules.helper.helper import create_video_from_images, get_framerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 - Background Subtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo criado com sucesso: sub_background.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminho para o vídeo\n",
    "video_path  = \"input\\\\Teste.mp4\"\n",
    "save        = \"output\\\\sub_background\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "prev_gray = None\n",
    "idx = 0\n",
    "\n",
    "img_before  = None\n",
    "background_stack = []  # Para armazenar frames sem movimento\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if type(img_before) != type(None):\n",
    "        \n",
    "        # Grayscale e equalização\n",
    "        gray_prev = cv2.equalizeHist(cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY))\n",
    "        gray_curr = cv2.equalizeHist(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        # Redução de ruído\n",
    "        gray_prev = cv2.GaussianBlur(gray_prev, (5, 5), 0)\n",
    "        gray_curr = cv2.GaussianBlur(gray_curr, (5, 5), 0)\n",
    "\n",
    "        # Subtração e limiarização\n",
    "        diff = cv2.absdiff(gray_prev, gray_curr)\n",
    "        _, motion_mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Remover pequenos ruídos\n",
    "        motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "        # Inverter para pegar áreas \"estáticas\"\n",
    "        static_mask = cv2.bitwise_not(motion_mask)\n",
    "\n",
    "        # Aplicar máscara estática ao frame atual\n",
    "        static_pixels = cv2.bitwise_and(frame, frame, mask=static_mask)\n",
    "        background_stack.append(static_pixels)\n",
    "\n",
    "        # Salvar máscara de movimento\n",
    "        cv2.imwrite(os.path.join(save, f\"results{idx}.jpg\"), motion_mask)\n",
    "\n",
    "    img_before = frame.copy()\n",
    "    idx+=1\n",
    "\n",
    "# # Gerar background final pela mediana dos frames estáticos\n",
    "# if background_stack:\n",
    "#     background_array = np.stack(background_stack, axis=3)\n",
    "#     background_final = np.median(background_array, axis=3).astype(np.uint8)\n",
    "#     cv2.imwrite(os.path.join(\"background_final.jpg\"), background_final)\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"sub_background.mp4\"\n",
    "frame_rate = 13  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 - calcOpticalFlowFarneback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo criado com sucesso: motion_flow.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminho para o vídeo\n",
    "video_path  = \"input\\\\Teste.mp4\"\n",
    "save        = \"output\\\\optical_flow\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "prev_gray = None\n",
    "idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_gray is not None:\n",
    "        \n",
    "        # Calcula o fluxo óptico denso\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray,      # imagem anterior (grayscale)\n",
    "            gray,           # imagem atual (grayscale)\n",
    "            None,           # matriz de fluxo (pode ser None)\n",
    "            pyr_scale=0.25, # escala da pirâmide de imagem\n",
    "            levels=3,       # número de níveis da pirâmide\n",
    "            winsize=10,     # tamanho da janela\n",
    "            iterations=5,   # número de iterações por nível\n",
    "            poly_n=7,       # tamanho da vizinhança para polinômio\n",
    "            poly_sigma=1.5, # sigma (desvio padrão) da Gaussiana usada\n",
    "            flags=0         # opções adicionais (geralmente 0)\n",
    "        )\n",
    "\n",
    "        # Converte o fluxo em magnitude e ângulo\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "        # Cria máscara binária para movimento baseado na magnitude\n",
    "        movement_mask = cv2.threshold(mag, 1.5, 255, cv2.THRESH_BINARY)[1]\n",
    "        movement_mask = movement_mask.astype(np.uint8)\n",
    "\n",
    "        # Salva a máscara de movimento\n",
    "        cv2.imwrite(os.path.join(save, f\"results{idx}.jpg\"), movement_mask)\n",
    "\n",
    "        # # (Opcional) Mostra o vetor de movimento com cor HSV\n",
    "        # hsv = np.zeros_like(frame)\n",
    "        # hsv[..., 1] = 255\n",
    "        # hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        # hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # cv2.imwrite(os.path.join(save, f\"flow_visual_{idx:04}.jpg\"), flow_rgb)\n",
    "\n",
    "    prev_gray = gray\n",
    "    idx+=1\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"motion_flow.mp4\"\n",
    "frame_rate = get_framerate(video_path)  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3 - createBackgroundSubtractorKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo criado com sucesso: motion_knn.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminhos\n",
    "video_path = \"input\\\\Teste.mp4\"\n",
    "save = \"output\\\\knn_video\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Inicializar captura e detector KNN\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fgbg = cv2.createBackgroundSubtractorKNN(history=30, dist2Threshold=400, detectShadows=False)\n",
    "\n",
    "# Kernels para refinamento de máscaras\n",
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "\n",
    "area = 100  # Área mínima para contornos (ajustar conforme necessário)\n",
    "\n",
    "idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Ajuste de constraste\n",
    "    frame_blur = cv2.GaussianBlur(frame, (3, 3), 0)\n",
    "    frame_detail = cv2.detailEnhance(frame_blur, sigma_s=30, sigma_r=0.1)\n",
    "\n",
    "    # Grayscale e equalização\n",
    "    frame_equalized = cv2.equalizeHist(cv2.cvtColor(frame_detail, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # Redução de ruído\n",
    "    frame_blur = cv2.GaussianBlur(frame_equalized, (3, 3), 0)\n",
    "\n",
    "    # Limpeza de ruído (leve e rápida)\n",
    "    frame_open = cv2.morphologyEx(frame_blur, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "    frame_close = cv2.morphologyEx(frame_open, cv2.MORPH_CLOSE, kernel_close, iterations=2)\n",
    "    \n",
    "    # Aplicar subtração de fundo KNN\n",
    "    fgmask = fgbg.apply(frame_close)\n",
    "\n",
    "    # Detectar contornos dos objetos claramente definidos\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Criar máscara vazia para contornos precisos\n",
    "    precise_mask = np.zeros_like(fgmask)\n",
    "\n",
    "    # Preencher contornos na máscara\n",
    "    for cnt in contours:\n",
    "        # Ignorar pequenos ruídos\n",
    "        if cv2.contourArea(cnt) >= area:  \n",
    "            cv2.drawContours(precise_mask, [cnt], -1, 255, -1)  # Preenche o objeto detectado\n",
    "        else:\n",
    "            cv2.drawContours(precise_mask, [cnt], -1, 0, -1)  # Preenche o objeto detectado\n",
    "\n",
    "    # Extrair objetos em movimento (sem borrões)\n",
    "    moving_objects = cv2.bitwise_and(frame, frame, mask=precise_mask)\n",
    "\n",
    "    # Opcional: Desenhar caixa delimitadora ao redor dos objetos (facilita identificação)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) >= area:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Salvar resultado com objetos definidos\n",
    "    cv2.imwrite(os.path.join(save, f\"results_{idx:04}.jpg\"), frame)\n",
    "\n",
    "    idx += 1\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "# Criar vídeo final\n",
    "image_folder = save\n",
    "output_video_path = \"motion_knn.mp4\"\n",
    "frame_rate = get_framerate(video_path)\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 - Motrackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python==4.5.3.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"input\\\\Teste.mp4\")\n",
    "\n",
    "# Trackers atualizados para a versão atual do OpenCV\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "    \"csrt\":         cv2.legacy.TrackerCSRT_create,\n",
    "    # \"kcf\":          cv2.legacy.TrackerKCF_create,\n",
    "    \"boosting\":     cv2.legacy.TrackerBoosting_create,\n",
    "    # \"mil\":          cv2.legacy.TrackerMIL_create,\n",
    "    \"tld\":          cv2.legacy.TrackerTLD_create,\n",
    "    \"medianflow\":   cv2.legacy.TrackerMedianFlow_create,\n",
    "    \"mosse\":        cv2.legacy.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "# Agora gerenciamos múltiplos trackers manualmente\n",
    "trackers = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1090, 600))\n",
    "\n",
    "    boxes = []\n",
    "    new_trackers = []\n",
    "\n",
    "    for tracker in trackers:\n",
    "        success, box = tracker.update(frame)\n",
    "        if success:\n",
    "            boxes.append(box)\n",
    "            new_trackers.append(tracker)\n",
    "\n",
    "    trackers = new_trackers\n",
    "\n",
    "    # Desenha caixas atualizadas\n",
    "    for box in boxes:\n",
    "        (x, y, w, h) = [int(v) for v in box]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'TRACKING', (x + 10, y - 3), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "    k = cv2.waitKey(30)\n",
    "\n",
    "    if k == ord(\"s\"):\n",
    "        roi = cv2.selectROI(\"Frame\", frame, fromCenter=False, showCrosshair=True)\n",
    "        tracker = OPENCV_OBJECT_TRACKERS['tld']()\n",
    "        tracker.init(frame, roi)\n",
    "        trackers.append(tracker)\n",
    "\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT VIDEO TO IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos\n",
    "video_path = \"input\\\\Teste.mp4\"\n",
    "save = \"output\\\\splited\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Inicializar captura e detector KNN\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Salvar resultado com objetos definidos\n",
    "    cv2.imwrite(os.path.join(save, f\"results_{idx:04}.jpg\"), frame)\n",
    "    idx+=1\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_legacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
