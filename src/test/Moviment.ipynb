{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉ-AMBULO - IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from modules.helper.helper import create_video_from_images, get_framerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 - Background Subtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path        = \"output\\\\*.jpg\"\n",
    "save        = \"output\\\\sub_background\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "files       = sorted(glob.glob(path), key=lambda x: int(\"\".join(filter(str.isdigit, os.path.basename(x)))))\n",
    "\n",
    "img_before  = None\n",
    "background_stack = []  # Para armazenar frames sem movimento\n",
    "\n",
    "for idx, filename in enumerate(files):\n",
    "    frame = cv2.imread(filename)\n",
    "\n",
    "    if img_before is not None:\n",
    "        # Grayscale e equalização\n",
    "        gray_prev = cv2.equalizeHist(cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY))\n",
    "        gray_curr = cv2.equalizeHist(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        # Redução de ruído\n",
    "        gray_prev = cv2.GaussianBlur(gray_prev, (5, 5), 0)\n",
    "        gray_curr = cv2.GaussianBlur(gray_curr, (5, 5), 0)\n",
    "\n",
    "        # Subtração e limiarização\n",
    "        diff = cv2.absdiff(gray_prev, gray_curr)\n",
    "        _, motion_mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Remover pequenos ruídos\n",
    "        motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "        # Inverter para pegar áreas \"estáticas\"\n",
    "        static_mask = cv2.bitwise_not(motion_mask)\n",
    "\n",
    "        # Aplicar máscara estática ao frame atual\n",
    "        static_pixels = cv2.bitwise_and(frame, frame, mask=static_mask)\n",
    "        background_stack.append(static_pixels)\n",
    "\n",
    "        # Salvar máscara de movimento\n",
    "        cv2.imwrite(os.path.join(save, f\"results{idx}.jpg\"), motion_mask)\n",
    "\n",
    "    img_before = frame.copy()\n",
    "\n",
    "# # Gerar background final pela mediana dos frames estáticos\n",
    "# if background_stack:\n",
    "#     background_array = np.stack(background_stack, axis=3)\n",
    "#     background_final = np.median(background_array, axis=3).astype(np.uint8)\n",
    "#     cv2.imwrite(os.path.join(\"background_final.jpg\"), background_final)\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"Detect.mp4\"\n",
    "frame_rate = 13  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 - calcOpticalFlowFarneback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o vídeo\n",
    "video_path  = \"input\\\\Teste.mp4\"\n",
    "save        = \"output\\\\optical_flow\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "prev_gray = None\n",
    "idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_gray is not None:\n",
    "        \n",
    "        # Calcula o fluxo óptico denso\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray,      # imagem anterior (grayscale)\n",
    "            gray,           # imagem atual (grayscale)\n",
    "            None,           # matriz de fluxo (pode ser None)\n",
    "            pyr_scale=0.25, # escala da pirâmide de imagem\n",
    "            levels=3,       # número de níveis da pirâmide\n",
    "            winsize=10,     # tamanho da janela\n",
    "            iterations=5,   # número de iterações por nível\n",
    "            poly_n=7,       # tamanho da vizinhança para polinômio\n",
    "            poly_sigma=1.5, # sigma (desvio padrão) da Gaussiana usada\n",
    "            flags=0         # opções adicionais (geralmente 0)\n",
    "        )\n",
    "\n",
    "        # Converte o fluxo em magnitude e ângulo\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "        # Cria máscara binária para movimento baseado na magnitude\n",
    "        movement_mask = cv2.threshold(mag, 1.5, 255, cv2.THRESH_BINARY)[1]\n",
    "        movement_mask = movement_mask.astype(np.uint8)\n",
    "\n",
    "        # Salva a máscara de movimento\n",
    "        cv2.imwrite(os.path.join(save, f\"results{idx}.jpg\"), movement_mask)\n",
    "\n",
    "        # # (Opcional) Mostra o vetor de movimento com cor HSV\n",
    "        # hsv = np.zeros_like(frame)\n",
    "        # hsv[..., 1] = 255\n",
    "        # hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        # hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # cv2.imwrite(os.path.join(save, f\"flow_visual_{idx:04}.jpg\"), flow_rgb)\n",
    "\n",
    "    prev_gray = gray\n",
    "    idx+=1\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"motion_flow.mp4\"\n",
    "frame_rate = get_framerate(video_path)  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3 - createBackgroundSubtractorKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos\n",
    "video_path = \"input\\\\Teste.mp4\"\n",
    "save = \"output\\\\knn_video\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Inicializar captura e detector KNN\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fgbg = cv2.createBackgroundSubtractorKNN(history=30, dist2Threshold=400, detectShadows=False)\n",
    "\n",
    "# Kernels para refinamento de máscaras\n",
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "\n",
    "area = 100  # Área mínima para contornos (ajustar conforme necessário)\n",
    "\n",
    "idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Ajuste de constraste\n",
    "    frame_blur = cv2.GaussianBlur(frame, (3, 3), 0)\n",
    "    frame = cv2.detailEnhance(frame_blur, sigma_s=30, sigma_r=0.1)\n",
    "\n",
    "    # Ajuste automático de brilho\n",
    "    # Converter para escala de cinza para análise de brilho\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calcular o brilho médio\n",
    "    mean_brightness = np.mean(gray_frame)\n",
    "    # Definir brilho alvo (ajustar conforme necessário)\n",
    "    target_brightness = 90\n",
    "    # Calcular fator de ajuste\n",
    "    adjustment_factor = target_brightness / mean_brightness if mean_brightness > 0 else 1\n",
    "    # Aplicar ajuste de brilho\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=adjustment_factor, beta=0)\n",
    "\n",
    "    # Redução de ruído\n",
    "    frame_blur = cv2.GaussianBlur(frame, (7, 7), 0)\n",
    "    \n",
    "    # Grayscale e equalização\n",
    "    frame_equalized = cv2.equalizeHist(cv2.cvtColor(frame_blur, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # Aplicar subtração de fundo KNN\n",
    "    fgmask = fgbg.apply(frame_equalized)\n",
    "    \n",
    "    # Remover sombras (valores intermediários)\n",
    "    fgmask[fgmask == 127] = 0\n",
    "\n",
    "    # Limpeza de ruído (leve e rápida)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel_close, iterations=2)\n",
    "\n",
    "    # Detectar contornos dos objetos claramente definidos\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Criar máscara vazia para contornos precisos\n",
    "    precise_mask = np.zeros_like(fgmask)\n",
    "\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) >= area:  # Ignorar pequenos ruídos\n",
    "            cv2.drawContours(precise_mask, [cnt], -1, 255, -1)  # Preenche o objeto detectado\n",
    "\n",
    "    # Extrair objetos em movimento (sem borrões)\n",
    "    # moving_objects = cv2.bitwise_and(frame, frame, mask=precise_mask)\n",
    "\n",
    "    # Opcional: Desenhar caixa delimitadora ao redor dos objetos (facilita identificação)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) >= area:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Salvar resultado com objetos definidos\n",
    "    cv2.imwrite(os.path.join(save, f\"results_{idx:04}.jpg\"), precise_mask)\n",
    "\n",
    "    idx += 1\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "# Criar vídeo final\n",
    "image_folder = save\n",
    "output_video_path = \"motion_knn.mp4\"\n",
    "frame_rate = get_framerate(video_path)\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 - Motrackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"Trackers disponíveis em legacy:\", dir(cv2.legacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
