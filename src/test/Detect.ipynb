{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERIFICANDO SE TEM CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA disponível:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET >> https://universe.roboflow.com/force-iaope/cars-egrgd/dataset/1#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉ-AMBULO - IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "from modules.helper.helper import create_video_from_images, get_framerate\n",
    "\n",
    "# https://docs.ultralytics.com/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new YOLO model from scratch\n",
    "model = YOLO(\"yolo11n.yaml\")\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs # c:\\dev\\datasets\n",
    "results = model.train(\n",
    "    data=\"coco128.yaml\", \n",
    "    epochs=1000,                # Number of epochs to train\n",
    "    device=\"0\", \n",
    "    workers=2,                  # Number of workers for data loading\n",
    "    classes=[0, 1, 2, 3, 5, 7], # Alterar para as classes desejadas\n",
    "    imgsz=1024,                 # Image size for training (960x960) \n",
    "    batch=4,                    # Batch size\n",
    "    cache=True,                 # Cache images for faster training\n",
    "    save_period=5,              # Save model every 5 epochs\n",
    "    name=\"yolo11n_960_1000\",    # Alterar para o nome desejado \n",
    "    exist_ok=True,              # Overwrite existing model directory\n",
    "    project=\"runs/train\",       # Alterar para o diretório desejado\n",
    "    resume=True,                # Continue training from the last checkpoint\n",
    "    patience=10,                # Early stopping patience\n",
    "    optimizer=\"AdamW\",          # Alterar para 'Adam' ou 'AdamW' se necessário\n",
    "    pretrained=True,            # Use True para carregar pesos pré-treinados\n",
    "    # hyp=\"data/hyp.scratch-low.yaml\",\n",
    ")\n",
    "\n",
    "# Validate the model on the validation set\n",
    "valid = model.val()\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# success = model.export(format=\"onnx\")\n",
    "\n",
    "# Save the trained model for future reuse\n",
    "model.save(\"trained_model/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.7 torch-2.6.0+cu118 CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\dev\\Contagem-Volumetrica\\runs\\detect\\train21\\weights\\best.pt' with input shape (1, 3, 960, 960) BCHW and output shape(s) (1, 84, 18900) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  12.2s, saved as 'c:\\dev\\Contagem-Volumetrica\\runs\\detect\\train21\\weights\\best.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (12.7s)\n",
      "Results saved to \u001b[1mC:\\dev\\Contagem-Volumetrica\\runs\\detect\\train21\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=c:\\dev\\Contagem-Volumetrica\\runs\\detect\\train21\\weights\\best.onnx imgsz=960  \n",
      "Validate:        yolo val task=detect model=c:\\dev\\Contagem-Volumetrica\\runs\\detect\\train21\\weights\\best.onnx imgsz=960 data=C:\\dev\\Contagem-Volumetrica\\venv\\Lib\\site-packages\\ultralytics\\cfg\\datasets\\coco128.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\dev\\\\Contagem-Volumetrica\\\\runs\\\\detect\\\\train21\\\\weights\\\\best.onnx'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\", dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for future reuse\n",
    "model.save(\"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST IN VIDEO 12s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o vídeo\n",
    "video_path  = \"input\\\\Teste.mp4\"\n",
    "\n",
    "save        = \"output\\\\detect\"\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(source=video_path)\n",
    "\n",
    "# Visualize the results\n",
    "for i, r in enumerate(results):\n",
    "    try:\n",
    "        # Plot results image\n",
    "        r = imutils.resize(r, width=700)\n",
    "        im_bgr = r.plot()  # BGR-order numpy array\n",
    "        if im_bgr is None:\n",
    "            print(f\"Resultado {i} não contém dados válidos para plotar.\")\n",
    "            continue\n",
    "        im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "        # Save results to disk\n",
    "        r.save(filename=os.path.join(save, f\"results{i}.jpg\"))\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro ao processar o resultado {i}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao processar o resultado {i}: {e}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"output_video.mp4\"\n",
    "frame_rate = get_framerate(video_path)  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
