{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET >> https://universe.roboflow.com/force-iaope/cars-egrgd/dataset/1#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉ-AMBULO - IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import queue as q\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from modules.helper.helper import create_video_from_images, get_framerate\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA disponível:\", torch.cuda.is_available())\n",
    "\n",
    "# https://docs.ultralytics.com/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new YOLO model from scratch\n",
    "model = YOLO(\"yolo11n.yaml\")\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs # c:\\dev\\datasets\n",
    "results = model.train(\n",
    "    data=\"data_train.yaml\",        # Arquivo de configuração do seu dataset\n",
    "    epochs=1000,                   # Número de épocas (pode ser ajustado conforme necessário)\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Verifica se há GPU disponível, caso contrário usa CPU\n",
    "    workers=2,                     # Número de workers para carregamento dos dados (aumentado para agilizar)\n",
    "    imgsz=512,                     # Tamanho das imagens (960x960)\n",
    "    batch=4,                       # Tamanho do batch (aumentado para melhor estabilidade, se sua GPU suportar)\n",
    "    cache=\"disk\",                  # Utiliza cache no disco para garantir resultados determinísticos\n",
    "    save_period=5,                 # Salva o modelo a cada 5 épocas\n",
    "    name=\"yolo11n_512_1000_max\",   # Nome da pasta de treinamento\n",
    "    exist_ok=True,                 # Sobrescreve o diretório existente, se houver\n",
    "    project=\"../../runs/train\",    # Diretório onde os resultados serão salvos\n",
    "    resume=False,                  # Não retoma de um checkpoint anterior\n",
    "    patience=10,                   # Aumenta a paciência do EarlyStopping para 50 épocas (ajuste conforme necessário)\n",
    "    optimizer=\"AdamW\",             # Otimizador SGD Adam AdamW pode melhorar a convergência\n",
    "    pretrained=True,               # Utiliza pesos pré-treinados\n",
    "    optimize=True,                 # Otimiza o modelo para melhor desempenho\n",
    "    classes=[1, 2, 3, 4],          # Escolhe as classes a serem treinadas (0: pessoas, 1: carros)\n",
    "    # hyp=\"data/hyp.scratch-low.yaml\" # Arquivo de hiperparâmetros; ajuste-o conforme o seu dataset\n",
    ")\n",
    "\n",
    "# Validate the model on the validation set\n",
    "valid = model.val()\n",
    "\n",
    "# Export the model to ONNX format\n",
    "success = model.export(format=\"onnx\", dynamic=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST IN VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for the thread to finish 1\n",
      "Wait for the thread to finish 2\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLO11 model\n",
    "model           = YOLO(\"..\\\\..\\\\runs\\\\train\\\\yolo11n_512_1000_max\\\\weights\\\\best.pt\")\n",
    "\n",
    "# Open the video file\n",
    "video_path      = \"input\\\\OneDrive\\\\Ponto 1\\\\Av. Mato Grosso x BR153 (Goiânia)\\\\Manhã\\\\Rec95_20250318065523_S_1.avi\" # \"input\\\\Teste.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Path to save the output frames\n",
    "save            = \"output\\\\detect\"\n",
    "shutil.rmtree(save)\n",
    "os.makedirs(save, exist_ok=True)\n",
    "\n",
    "# Initialize the count frame index and queue \n",
    "idx = 0\n",
    "queue = q.Queue(maxsize=100)  # Create a queue with a maximum size of 500\n",
    "\n",
    "# Function to save the frame as an image\n",
    "def SaveFrame():\n",
    "    while True:\n",
    "        frame, idx = queue.get()  # Get the frame and index from the queue\n",
    "        if frame is None or idx is None: break\n",
    "        cv2.imwrite(os.path.join(save, f\"frame_{idx}.jpg\"), frame)\n",
    "\n",
    "# Create and start threads for saving frames\n",
    "SaveFrameThreads = []\n",
    "for i in range(3):\n",
    "    thread = Thread(target=SaveFrame, daemon=True)  # Create a thread to save frames\n",
    "    thread.start()  # Start the thread\n",
    "    SaveFrameThreads.append(thread)  # Add the thread to the list\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        \n",
    "        try:\n",
    "            # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(\n",
    "                frame, \n",
    "                persist=True,\n",
    "                classes=[1, 2, 3, 4],   # Classes to track\n",
    "                conf=0.5,               # Confidence threshold\n",
    "                iou=0.45,               # IoU threshold\n",
    "                device= (\n",
    "                    \"cuda\" \n",
    "                    if torch.cuda.is_available() \n",
    "                    else \n",
    "                    \"cpu\"\n",
    "                ),                      # Verifica se há GPU disponível, caso contrário usa CPU\n",
    "                show=False,             # Show the results\n",
    "                save=False,             # Save the results\n",
    "                save_txt=False,         # Save results to text files\n",
    "                save_conf=False,        # Save confidence scores\n",
    "                save_crop=False,        # Save cropped images of detected objects\n",
    "                # save_dir=save,        # Directory to save results\n",
    "                # project=save,         # Project name\n",
    "                name=\"detect\",          # Name of the folder to save results\n",
    "                exist_ok=True,          # Overwrite existing results\n",
    "                line_width=1,           # Line thickness for bounding boxes\n",
    "                show_labels=True,       # Hide labels on bounding boxes\n",
    "                show_conf=True,         # Hide confidence scores on bounding boxes\n",
    "                half=True,              # Use half precision (FP16) for inference\n",
    "                dnn=False,              # Use OpenCV DNN for inference\n",
    "                vid_stride=1,           # Frame stride for video processing\n",
    "                agnostic_nms=False,     # Use class-agnostic NMS\n",
    "                augment=False,          # Use augmentation during inference\n",
    "                visualize=False,        # Visualize the results\n",
    "                verbose=False,          # Verbose output\n",
    "            )\n",
    "            \n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            if annotated_frame is None:\n",
    "                print(f\"Resultado {idx} não contém dados válidos para plotar.\")\n",
    "                continue\n",
    "            \n",
    "            im_rgb = Image.fromarray(annotated_frame[..., ::-1])  # RGB-order PIL image\n",
    "            queue.put((annotated_frame, idx))  # Add the frame to the queue for saving\n",
    "            idx += 1  # Increment the frame index\n",
    "        except ValueError as e:\n",
    "            print(f\"Erro ao processar o resultado {idx}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado ao processar o resultado {idx}: {e}\")\n",
    "\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Wait for all threads to finish processing\n",
    "for idx, thread in enumerate(SaveFrameThreads):\n",
    "    print(f\"Wait for the thread to finish {idx}\")\n",
    "    queue.put((None, None))\n",
    "    thread.join()  # Wait for all threads to finish\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "\n",
    "# Exemplo de uso\n",
    "image_folder = save\n",
    "output_video_path = \"output_video.mp4\"\n",
    "frame_rate = get_framerate(video_path)  # Substitua pelo frame rate desejado\n",
    "create_video_from_images(image_folder, output_video_path, frame_rate)\n",
    "\n",
    "# Abrir vídeo automaticamente após criação\n",
    "os.system(f\"start {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
